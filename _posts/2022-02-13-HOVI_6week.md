---
layout: post
title: HOVI의 6주차 기록
date: 2022-02-13 00:06:40
author: YeongHyeon-Kim
description:
categories: ["hovi"]
---

# HOVI의 6주차 기록

<br>

## 새로운 주제
표정 인식을 통한 의사 표현(전달) 앱

## 팀 멤버 🧑‍🤝‍🧑

-   김영현(Back-end)
-   박지수(Back-end)
-   이슬비(ML)
-   강인영(Android)


<br>

# 👻 2월 8일 정기 회의 👻
네 그렇습니다. HOVI팀은 새로운 주제를 정했습니다! 그것은 바로 "스마트폰 카메라📷를 사용해 사람의 표정😉을 인식하여 의사를 표현할 수 있는 앱" 이랍니다-! 긴 고민 끝에 다시 정해진 주제이니 앞으로는 쉬운 길만 남았다면 좋겠지만...🚶‍♀️ 역시나 개발은 쉽지 않다!!

## ✔ 논의 사항 
주제가 바뀌었으니 전반적인 서비스를 사용하게 될 대상은 누구이며, 구체적인 기능은 무엇인지와 함께 개발 순서, 해야 할 일 등을 정리해 보았습니다.
<br>
- 타겟  
거동이 불편하신 환자분들 또는 말하기를 통해 의사를 전달하는 것에 어려움이 있으신 분들
<br>
- 목적  
얼굴 표정 변화를 통한 의사 표현
<br>
- 기능  
사용자가 특정 표정이나 간단한 동작을 취했을 때 해당 동작에 매치된 의사표현 정보가 소리로 출력

<br>  

## 서비스 개발 단계 구체화
1. 얼굴 인식이 가능하도록 ML 기술을 개발한다.
2. 스마트폰을 카메라를 통해 실시간 얼굴 인식 및 표정 인식을 한다.
3. 인식 정보와 의사 표현 정보를 매칭하여 음성🔊으로 출력한다.  
+) 추후 간호사 및 보호자에게 의사표현 정보를 담은 메시지나 알림 기능을 추가하면 좋을 것 같다!👍
    
<br>

## ◻◼ TO DO ◼◻
🌻 **백엔드**  
와이어프레임 구체화하여 그림 그리기 👩‍💻

🌼 **안드로이드**  
MLKit로 얼굴인식 해보기

🌷 **ML**   
tensorflow lite, OpenCV, Mediapipe 중에서 사용 툴 확정하기


<br>
<br>


# 🎈 2월 11일 중간 보고 🎈

## ✔ 진행 사항 보고

- **안드로이드**  
CameraX를 사용해서 스마트폰📱의 카메라 사용에 대해 탐구해 보았으며, MLKit와 함께 사용되는 CameraX 예제 실습을 진행해 보았습니다.

- **백엔드**  
백엔드에서 어떤 방법으로 통신을 할지, 어떠한 정보들을 서버에서 가지고 있어야 할지 등에 대해서 고민🙃해보았습니다.
스프링 코드를 만들어본지 오래되어 빠른 복습이 필요할 것 같습니다...

- **ML**   
우리의 앱을 만들기 위해서는 tensorflow lite, MLKit, Mediapipe, OpenCV 중에서 어떤 것을 사용해야 할지에 대한 탐구🔎를 하였습니다.

<br>  

## 서비스 구체화
- **안드로이드**  
실시간으로 표정 변화를 분석하여 행동의 결과를 서버에 전달. ex) 왼쪽 눈 3초 이상 감은게 감지 되면 서버에 이벤트 보내기

- **백엔드**  
각 스마트폰마다 가지는 디바이스 아이디로 유저를 구분하는 DB 구성

- **ML**   
이슬비 화이팅!

<br> 
## ◻◼ TO DO ◼◻

🌻 **백엔드**  
- 영현 : 스프링 API 만들어보기 & EC2 만들어두기
- 지수 : 네이버 CLOVA 음성 사용 방법 확인하기

🌼 **안드로이드**  
- MLKit와 CameraX 예제를 자세히 분석해 보기
- ML, 안드로이드, 스프링, AWS를 어떻게 조화롭게 사용할지 찾아보기

🌷 **ML**   
- 랜드마크 따는 방법 찾아보기
- 표정 인식 모델 완성하기
- 학습을 위한 데이터를 추가하는 방법 알아보기

<br>

---
<br>

주제가 바뀌어 버려서 HOVI👀라는 이름을 그대로 가져갈지 아직은 알 수 없지만 이전의 HOVI 앱을 만들기 위해서 했던 노력도 다 도움이 될 거라고 생각합니다!! 물론 마감 기간이 다가오고 있지만 우리 호비팀은 할 수 있다~! 파이팅💪

<br>
