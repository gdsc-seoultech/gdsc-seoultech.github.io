---
layout: post
title:  04 데이터로 뭐를 할까? 📊
date:   2022-11-03 00:00:00
author: keonju
categories: ["2nd_term"]
tags: ["seminar"]
---

중간고사 끝나고 첫 세미나 시간입니다!  
이번 시간에는 가볍게 데이터에 대한 내용들을 찍먹해보겠습니다!  
<br><br>

# 목차  

1. 분석가? 엔지니어? 사이언티스트?  
2. 머신러닝? 딥러닝? AI?   
3. 머신러닝 학습 방법 종류  
4. 왜 딥러닝인가?  
5. 딥러닝 모델 종류  
6. 딥러닝 활용 분야  
<br>
<br>

# 1. 분석가? 엔지니어? 사이언티스트?  

데이터 분석가, 엔지니어, 사이언티스트, 머신러닝 엔지니어..  
데이터에 관한 다양한 직업들이 있습니다!  

첫번째 주제는 데이터 업무 FLOW에서 어떤 직업들이 어떤 일을 하는지 알아보았습니다. 
<br> 

![20221108_234616](https://user-images.githubusercontent.com/54880474/200595317-d5734666-6e8c-440d-9ec9-903424c63522.png)

### 데이터 Flow 
데이터 획득 -> 정제 -> 모델 학습 -> 분석/시각화 -> 서비스 배포 순으로 이루어집니다.  
<br>

### 데이터 엔지니어  
데이터를 수집, 저장, 유지, 보수하고 분석에 사용할 수 있도록 만들어주는 역할을 합니다. 또한 지속적으로 데이터를 수집하기 위한 구조를 만듭니다.  

따라서 리눅스, 클라우드, 분산시스템, SQL과 같은 기술을 요구합니다.  
<br>

### 데이터 사이언티스트
데이터를 이용해 서비스나 기능을 개발합니다. 어떤 비즈니스 인사이트를 도출한다거나 모델링을 이용한 예측 분석을 주로 합니다.  

따라서 ML, DL, 통계, 도메인 지식을 요구합니다.  
<br>

### 데이터 분석가
코호트 분석과 같이 사용자 분석이나 효율성과 같은 측면을 통계적 지식과 시각화를 통해 분석합니다.  

따라서 SQL, 통계, 파이썬, R, 시각화와 같은 기술을 요구합니다.  
<br>

### 머신러닝 엔지니어
최신 기계 학습 모델을 연구하고 프로덕션에 배포, 실행할 수 있도록 소프트웨어를 만드는 역할을 합니다.  

따라서 파이썬, DL, CV, NLP와 같은 기술을 요구합니다.  
<br>
<br>

# 2. 머신러닝? 딥러닝? AI?  

머신러닝? 딥러닝? AI? 다들 이야기하는데 무엇이 다를까요?  
<br>
![20221108_235455](https://user-images.githubusercontent.com/54880474/200597600-225e5081-e6ad-4384-bbb7-2c441ff879f4.png)

보통 AI > ML > DL 순으로 큰 범위를 의미합니다.  
<br>

### AI
the effort to automate intellectual tasks normally performed by humans” - François Chollet 

### ML
“field of study that gives computers the ability to learn without being explicitly programmed”-Arthur Samuel

케라스의 창시자와 ML이라는 용어의 대중화를 이끈 분은 각각 AI와 ML을 다음과 같이 정의했습니다. 머신러닝은 인간이 수행하는 지적 작업을 자동화할 수 있도록 컴퓨터에게 학습할 수 있는 능력을 주는 연구입니다.  

그래서 프로그래밍이 규칙과 데이터를 통해 해답을 얻어내는 과정이라면 머신러닝은 데이터와 해답을 가지고 컴퓨터가 어떤 규칙을 학습하도록 프로그래밍을 진행합니다.  

딥러닝은 머신러닝의 일부인 인공신경망에서 더 발전된 형태를 의미합니다.  
<br>
<br>

# 3. 머신러닝 학습 방법 종류    

그렇다면 머신러닝에는 어떤 학습 방법이 있을까요?  
굉장히 많은 학습 방법들이 있지만 크게 지도, 비지도, 강화학습 세가지로 분류됩니다.  
<br>
![20221109_202228](https://user-images.githubusercontent.com/54880474/200817686-36055234-96a7-4c17-9a9a-4089c7d8178b.png)

### 지도학습 
지도학습(Supervised Learning)이란 정답(Label)을 알려주는 학습 방법입니다.  
분류와 회귀 두가지 방법이 대표적으로 있습니다.  

분류(Classification)는 데이터와 정답 두 정보를 모델에 제공하여 최적의 구분 방법을 찾는 방식입니다.  
회귀(Regression)는 데이터의 특징과 값 (Label) 사이의 상관관계를 통해 값을 예측하는 방식입니다.  

### 비지도학습
비지도학습(Unsupervised Learning)은 정답(Label)이 없지만 모델이 데이터에서 패턴이나 특징, 구조같은 규칙성을 찾는 방식입니다.  

군집화(Clustering)은 데이터를 비슷한 것끼리 묶어주는 방법입니다. 분류는 정답을 통해 데이터를 나눠주었다면 군집화는 정답이 없기 때문에 밀도나 거리를 기반으로 데이터를 나눠줍니다.  
연관규칙(Association Rule)은 변수들 간의 관계를 발견하기 위한 방법입니다. 등장 빈도나 등장 순서와 같은 정보들을 통해 변수들 간의 관계를 찾아냅니다.  
차원 축소(Dimension Reduction)는 고차원의 데이터들을 저차원으로 바꿔줍니다. 하나의 데이터가 가지고있는 특징(정형 데이터의 column)이 많아지면 2D나 3D로 시각화를 하기 힘들며 차원의 저주라는 문제가 발생할 가능성이 있습니다. 이런 경우 차원 축소를 통해 데이터의 차원을 줄여줍니다.  

### 강화학습
강화학습은 어떤 환경(environment) 안에서 정의된 주체(agent)가 현재 상태(state)를 관찰하여 선택할 수 있는 행동(action)들 중에서 가장 최대의 보상(reward)을 가져다주는 행동이 무엇인지 학습하는 방법입니다.  

![20221109_203538](https://user-images.githubusercontent.com/54880474/200820249-a9566e17-41ee-4989-ac05-4ac18bd2cab0.png)
<br>
<br>

# 4. 왜 딥러닝인가?    

![20221109_203715](https://user-images.githubusercontent.com/54880474/200820513-1787f94b-1121-4ba9-b6cf-27d314b28a36.png)

딥러닝의 발전에는 DNN, GPU, Big Data 세가지 요소가 크게 작용했다고 알려져있습니다.  

1986년 MLP와 오차역전파가 발표된 이후 퍼셉트론의 문제를 해결하면서 더 깊은 신경망을 만들 수 있었습니다. 하지만 이 때 만들어진 모델은 10개의 숫자를 인식하는 모델을 학습하는 시간만 3일이 걸릴 정도로 하드웨어의 연산 능력이 떨어졌습니다. 따라서 SVM과 같은 머신러닝 모델들이 각광받았습니다.  

이런 연산 능력을 해결한 방법은 GPU였습니다. GPU는 CPU와 달리 병렬 연산을 지원하기 때문에 숫자 연산들로 이루어진 딥러닝 모델에 적합하였습니다. GPU는 2012년 AlexNet이 발표되면서 많은 데이터를 더 빠른 속도로 학습할 수 있었고 딥러닝의 발전 속도 빨라졌습니다. NPU나 TPU와 같은 딥러닝 연산에 더 적합하게 만든 하드웨어들도 개발되고 있습니다.  

마지막은 빅데이터입니다. 머신러닝의 경우 데이터 양이 많아지더라도 특정 퍼포먼스에서 멈추는 모습을 보였지만 딥러닝의 경우 많은 양의 데이터를 학습해도 꾸준히 성능이 올라가는 모델을 만들 수 있습니다. 깃허브와 OpenAI가 발표한 코파일럿의 경우 수테라 바이트의 코드가 학습에 사용되었다고 합니다. 또한 초거대 언어모델인 GPT-3의 경우 4990억 개의 데이터셋을 학습하였다고 알려져있습니다.  
<br>

![20221109_204532](https://user-images.githubusercontent.com/54880474/200822201-e4d4c05e-5a57-4d4e-83df-8f5186406c3b.png)

또한 딥러닝은 기존의 패턴인식 모델들과 다르게 특성 추출이 필요없으며 Low-Level부터 High-Level까지 추출할 수 있다는 장점에서 Representation Learning으로 불립니다. 이런 부분에서 기존 모델들보다 딥러닝을 통한 다양한 응용이 이루어지고 있습니다.  
<br>
<br>

# 5. 딥러닝 모델 종류    

딥러닝 모델도 굉장히 많지만 여기서는 가장 대표적인 두 모델을 간단하게 소개해드리겠습니다.  

### Convolutional Neural Networks (CNN)

![20221109_210736](https://user-images.githubusercontent.com/54880474/200826647-4320fdad-63be-474f-bd47-9c94a342af67.png)

CNN은 convolution이라는 합성곱 연산을 통해서 특징을 추출하는 모델입니다.  
그림에서 보이는 것처럼 convolution이 데이터의 지역들과 합성곱 연산을 통해 그 지역의 특징을 추출합니다. 이런 지역적 특징을 추출하는 점에서 이미지를 다루는 곳에 많이 사용되었습니다.  

### Recurrent Neural Networks (RNN)

![20221109_211143](https://user-images.githubusercontent.com/54880474/200827375-54515400-eeac-4016-a486-7575d2fdf6a7.png)

RNN은 데이터를 순차적으로 다룹니다. 하나의 데이터가 모델에 들어가면 그 다음 데이터와 이전 데이터의 결과값이 다시 전달됩니다. 그림에서 보이는 것처럼 학습했던 값을 다시 전달해주면서 연속된 데이터를 처리하는 것에 적합하게 설계되어있습니다. 그래서 주로 시계열, 자연어, 음성과 같은 연속된 데이터에 많이 이용되었습니다.  

### Transformer

![20221109_211444](https://user-images.githubusercontent.com/54880474/200827941-743baa6b-6837-431b-a563-6668d02d9b9d.png)

Transformer은 구글에서 2017년 발표한 "Attention is all you need"에서 소개된 방식입니다. 기존 seq2seq 구조의 인코더-디코더를 따르면서도 Attention만을 이용해 구현한 모델입니다.  
이 모델을 설명하기엔 인코더-디코더, seq2seq와 같이 많은 내용들이 필요합니다.  
하지만 자연어처리를 위해 개발된 모델이지만 현재는 이미지, 음성, 강화학습 등 거의 대부분 분야에 Transformer 구조를 채택하려는 연구가 진행되고 있을 정도로 파급력이 컸던 모델입니다.  
또한 초거대 AI라고 불리는 대규모 언어 모델들 또한 이 모델을 기점으로 더 발전하게 되었습니다.  

<br>
<br>

# 6. 딥러닝 활용 분야    

딥러닝은 다양한 분야에서 사용되고 있습니다. 예전에는 자연어, 이미지 각 분야에 국한되었다면 요즘에는 Text-to-Image, Text-to-Speech와 같은 연구도 많이 진행되고 있습니다.  

![20221109_213320](https://user-images.githubusercontent.com/54880474/200831584-c81a1203-f32f-4336-a69d-b2578ad86b5e.png)
![20221109_213306](https://user-images.githubusercontent.com/54880474/200831588-0f0cef63-2025-4dfe-9991-a1a64c86b542.png)

이외에 더 많은 연구 주제들을 보고 싶다면 https://paperswithcode.com/에서 확인하실 수 있습니다.  
<br>
<br>

# 마무리

이렇게 4번째 세미나 데이터로 무엇을 할까?를 마치게 되었습니다.  
이번 세미나를 통해 자신이 머신러닝, 딥러닝을 모르더라도! 아이디어가 생겼을 때 어떤 접근을 하면 좋을지 알게되는 세미나였으면 좋겠습니다!!  


